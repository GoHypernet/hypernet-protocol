# Vector Protocol

Protocol is where the core Vector framework is defined. Protocol takes in params via method calls, uses them to make updates to its replicated state with a channel peer, and stores resulting commmitments in store.

Contents:

- [Developing and Running Tests](https://github.com/connext/vector/tree/master/modules/protocol#developing-and-running-tests)
- [Core Principles](https://github.com/connext/vector/tree/master/modules/protocol#core-principles)
- [Sync Protocol](https://github.com/connext/vector/tree/master/modules/protocol#sync)
- [Update Types](https://github.com/connext/vector/tree/master/modules/protocol#update-types)

## Developing and Running Tests

In `~/vector` (root), run:

- `make protocol` to build the protocol
- `make test-protocol` to run the unit tests

## Core Principles

Vector aims to be an _extremely simple_ state channel protocol. Both parties follow a single flow to make updates:

1. **Leader Election** -- this is done using a distributed lock implementation. Peers queue updates on the lock and execute them serially.
2. **Update Generation** -- a proposed update is generated by the sender in-memory
3. **Syncronization** -- the sender's update is dispatched over the wire. Receiver validates the update, merges the update with their channel, stores the channel, and then acks. Sender receives the ack and stores.

We use the following design principles:

- Vector uses leader election -> consensus to manage updates to both peers' replicated stores. To keep things simple (at the cost of some additional messaging overhead), we have chosen _not_ to use a CRDT + turn taking pattern like StateChannels.
- All updates in a channel fall into one of four types of operations: `setup` sets up a new channel between two peers, `deposit` reconciles pending onchain deposits with offchain balance, `create` creates a new conditional transfer with the peer, `resolve` resolves a previously created conditional transfer.
- All updates are single-round-trip and associated with a monotonically incrementing nonce.
- The protocol does _not_ make assumptions about message delivery to the counterparty. Each update additionally contains information about the `n-1` (previous) update. This means that if, for whatever reason, the counterparty failed to properly synchronize the last update, it is possible for them "recover" and do so within the single round trip of the next update. In other words, the protocol will **always** recover if a peer's state gets out of sync.
- All generated updates are matched to corresponding validators, that ensure that the peer's updates were generated and signed correctly.
- Lastly, as an implementation detail, we utilize an extra-protocol `isAlive` messaging roundtrip. This happens entirely outside of the lock and is used as a liveness check when peers reconnect.

## Sync Protocol

At the core of Vector lies `sync`. Unlike in other state channel systems, there is only a **single** protocol -- `sync` is used both when a sender wants to propose a new update to the replicated state, and _also_ when peer state has diverged. Because updates are monotonic (nonce += 1), there are only a very limited number of cases within which party states possibly diverge.

For this reason, `sync` takes a higher degree of control over message delivery than other state channel protocols do. Outbound messages are retried on a timer if they fail, inbound ones are idempotent. Higher-nonced inbound messages are checked against the `ChannelState` latest nonce and dropped if they are duplicates, or saved to store if they aren't.

## Update Types

All channel updates fall into one of 4 types. Each update type is responsible for generating and storing one [double-signed commitment](https://github.com/connext/vector/blob/master/modules/contracts/README.md#commitments).

Note that there is no specific update for `Withdraw`. That is because a withdraw op can be constructed in an easy and generalizeable way using `Create` and `Resolve` similar to what we currently do in CF.

### Setup

Like in CF, creating a new channel simply involves calculating a `channelId` which is the CREATE2 address at which a proxy to the `Multisig.sol` contract will be deployed.

After that, Alice and Bob sign a `0` nonce update which sets up the channel state between them. This type of update is only ever needed once. Unlike in CF, `setup` does not actually sign a unique commitment, but instead signs a `ChannelCommitment` just like all of the other updates. Theoretically, this means that we don't actually _need_ a setup-specific commitment. However, it can be desirable to do this so that a peer can know that a new connection has been created that they can choose to accept.

Setup also performs one more highly critical task -- the channel initiator/responder, as defined in `participants[]`, are mutually agreed upon. This is a necessary component of how deposits should occur.

### Deposit

A deposit update should occur after deposits have been send to chain (either by calling the `depositA` function for the channel initiator, or simply sending funds to the multisig for the channel responder).

The deposit update is used to confirm an already-mined deposit tx into the channel `balance`. To do this safely, the following must occur:

1. The update initiator's balance must be incremented by the deposit amount (calculating new balances for each party using onchain data as described in the [Depositing and Withdrawing](https://github.com/connext/vector/blob/master/modules/contracts/README.md#depositing-and-withdrawing) writeup). Note that this is per-assetId, so a new assetId may need to be added to the `assetId` array.
2. The `processedDepositsA` and `processedDepositsB` must be updated.
3. The channel nonce must be updated by 1.
4. A new `ChannelCommitment` must be generated using the above and signed by both parties.
5. Set this update to `state.latestUpdate`.

### Create

A create update should occur when both parties want to create a new conditional transfer.

The create update must do the following:

1. Decrement the channel state `balance` on one (or both) sides by the amount that will be locked in the transfer (indexed by assetId).
2. Update the channel nonce by 1.
3. Create a new `TransferState` with a status of CREATED, passing in the correct params.
4. Hash the `TransferState` and add it to the merkle root in the new channel state.
5. Generate a duoblesigned `ChannelCommitment`.
6. Set this update to `state.latestUpdate`.

### Resolve

A resolve update should occur when both parties want to resolve a conditional transfer and reintroduce it's balances back to the main channel balance.

Should do the exact oppositve of the `create` update above.
